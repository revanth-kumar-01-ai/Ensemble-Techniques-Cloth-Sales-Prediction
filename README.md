# Ensemble-Techniques-Cloth-Sales-Prediction
ğŸ›ï¸ Ensemble Learning: Implement Bagging, Boosting (AdaBoost, Gradient Boost, XGBoost), Stacking, and Voting on the dataset to enhance accuracy. ğŸ“Š Model Optimization: Train, test, and compare models using performance metrics. Apply GridSearchCV to find the best hyperParameters for improved predictions. ğŸš€

## ğŸš€ WorkFlow  
1ï¸âƒ£ **Update** ğŸ› ï¸ `config.yaml`  
2ï¸âƒ£ **Update** ğŸ“œ `schema.yaml`  
3ï¸âƒ£ **Update** âš™ï¸ `params.yaml`  
4ï¸âƒ£ **Update** ğŸ—ï¸ **the entity**  
5ï¸âƒ£ **Update** ğŸ“ **the configuration manager in `src/config`**  
6ï¸âƒ£ **Update** ğŸ§© **the components**  
7ï¸âƒ£ **Update** ğŸ”„ **the pipeline**  
8ï¸âƒ£ **Update** ğŸš€ `main.py`  
9ï¸âƒ£ **Update** ğŸŒ `app.py`  

## ğŸ“Œ **CRISP Methodology**  
âœ… **Business & Data Understanding** ğŸ“ŠğŸ”  
âœ… **Data Preparation** ğŸ§¹ğŸ“‚  
âœ… **Model Building** ğŸ¤–âš™ï¸  
âœ… **Model Evaluation** ğŸ“ˆâœ…  
âœ… **Model Deployment** ğŸš€ğŸ’»  
âœ… **Maintenance & Monitoring** ğŸ› ï¸ğŸ‘€  

## ğŸ“‚ **Business & Data Understanding**  

### ğŸ“Œ **Problem Statement**  
A **cloth manufacturing company** ğŸ­ wants to identify key attributes that contribute to **high sales** ğŸ“ˆ. The goal is to build **Decision Tree** ğŸŒ³ and **Random Forest** ğŸŒ² models, with **Sales** as the **target variable**, which must first be **converted into a categorical variable** ğŸ¯.  

### ğŸ¯ **Business Objectives & Constraints**  
âœ… **Business Objective:** Maximize profits ğŸ’°  
âœ… **Business Constraint:** Minimize the time required to identify key attributes â³  

### ğŸ“Š **Success Criteria**  
- **ğŸ“ˆ Business Success Criteria:** Increase sales by **20%**  
- **ğŸ¤– ML Success Criteria:** Achieve an accuracy of over **80%**  
- **ğŸ’° Economic Success Criteria:** Ensure business profits exceed **$3,000 USD**  

## ğŸ“‚ **Data Understanding**  

The dataset is provided by a **trusted institute** ğŸ›ï¸ and contains:  
- **11 features** ğŸ“Š  
- **400 rows** ğŸ“  

### ğŸ”¢ **Feature Names & Descriptions**  
- **Sales** ğŸ“ˆ â€“ Target variable, product sales  
- **CompPrice** ğŸ’² â€“ Competitor's product price  
- **Income** ğŸ’° â€“ Customer's annual income  
- **Advertising** ğŸ“¢ â€“ Marketing budget spent  
- **Population** ğŸŒ â€“ Population in the area  
- **Price** ğŸ·ï¸ â€“ Product selling price  
- **ShelveLoc** ğŸ“Œ â€“ Shelf display location  
- **Age** ğŸ‚ â€“ Customerâ€™s age group  
- **Education** ğŸ“ â€“ Years of education  
- **Urban** ğŸ™ï¸ â€“ Urban or rural location  
- **US** ğŸ‡ºğŸ‡¸ â€“ Customer in the US


# ğŸ“Š Accuracy  

These are the **Ensemble Learning** model accuracies for the **Clothing Sales Prediction** project. Based on the results, **ğŸ”¥ Stacking is the preferred choice** as it has **low bias and variance**. âœ…  

### ğŸ“Œ Model Performance Comparison  

| ğŸš€ **Ensemble Method**                      | ğŸ¯ **Train Accuracy** | ğŸ“ˆ **Test Accuracy** |
|--------------------------------------------|----------------------|----------------------|
| ğŸ—³ï¸ **Voting**                              | 0.8833               | 0.9179               |
| ğŸ—ï¸ **Stacking**                            | 0.8917               | 0.9071               |
| ğŸ­ **Bagging (AdaBoost + RF as Estimators)** | 0.8583               | 0.9750               |
| ğŸŒ± **Bagging (Gradient Boosting)**          | 0.8500               | 0.9857               |
| ğŸš€ **Bagging (XGBoost Classifier)**         | 0.8500               | 0.9536               |

ğŸ“Œ **Conclusion:** Among all the ensemble methods tested, **Stacking** is chosen as the best model due to its **balanced bias-variance tradeoff**. ğŸ†ğŸ¯  



## ğŸ”— MLflow Link  

[Ensemble Techniques - Cloth Sales Prediction](https://dagshub.com/revanth-kumar-01-ai/Ensemble-Techniques-Cloth-Sales-Prediction.mlflow) ğŸš€


## ğŸš€ Streamlit App  

ğŸ”— [Ensemble Techniques - Cloth Sales Prediction](https://ensemble-techniques-cloth-sales-prediction-ba49kfhpnjfesfsy7pf.streamlit.app/) ğŸŒŸ  

